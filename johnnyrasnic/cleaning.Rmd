---
title: "Data Cleaning"
author: "Johnny Rasnic"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(GGally)
```

```{r}
hpc = read_csv(here::here("hpc.csv"))
#summary(hpc)

hpcdf = hpc |> 
  mutate(start = as.Date(`Fiscal Year Begin Date`),end = as.Date(`Fiscal Year End Date`)) |> 
  mutate(days = as.numeric(end - start)) |> 
  mutate(numBeds = `Total Bed Days Available`/days,id = row_number())
```

```{r}
hpc_clean = hpcdf |> 
  janitor::clean_names() |> 
  select(provider_ccn, days, number_of_beds,
         total_costs, rural_versus_urban, provider_type, type_of_control,
         fte_employees_on_payroll, total_days = total_days_v_xviii_xix_unknown,
         total_discharges = total_discharges_v_xviii_xix_unknown,
         total_income, total_assets,
         salaries = total_salaries_from_worksheet_a) |> 
  na.omit() |> 
  mutate(rural = ifelse(rural_versus_urban == "R", 1, 0),
         control_bin = case_when(
           type_of_control < 3 ~ "Voluntary",
           (type_of_control >= 3 & type_of_control < 7) ~ "Proprietary",
           type_of_control >= 7 ~ "Governmental"
         ),
         provider_bin = ifelse(provider_type < 3 |
                                 provider_type == 6,
                               "General", "Specialized"
                               ),
         ) |> 
  select(- c(rural_versus_urban, type_of_control, provider_type))

duplicates = hpc_clean |> 
  group_by(provider_ccn) |> 
  summarise(count = n()) |> 
  filter(count > 1)

dup = map_lgl(hpc_clean$provider_ccn, `%in%`, duplicates$provider_ccn)

hpc1 = hpc_clean |> 
  filter(!dup)

hpc2 = hpc_clean |> 
  filter(dup) |> 
  group_by(provider_ccn) |> 
  summarise(
    days = sum(days),
    number_of_beds = mean(number_of_beds),
    total_costs = sum(total_costs),
    fte_employees_on_payroll = mean(fte_employees_on_payroll),
    total_days = sum(total_days),
    total_discharges = sum(total_discharges),
    total_income = sum(total_income),
    total_assets = mean(total_assets),
    salaries = sum(salaries),
    rural = max(rural),
    control_bin = max(control_bin),
    provider_bin = max(provider_bin)
  )

hpc_all = bind_rows(hpc1, hpc2)

hpc_normalize = hpc_all |> 
  mutate(
    total_costs = total_costs/days,
    inpatients = total_days/days,
    total_discharges = total_discharges/days,
    total_income = total_income/days,
    salaries = salaries/days
    )
```

```{r}
hpc_dummies = hpc_normalize |> 
  select(-c(provider_ccn, days)) |> 
  mutate(
    costs_bin = ifelse(total_costs > median(total_costs), 1, 0)
    ) |> 
  tidytable::get_dummies(drop_first = TRUE) |> 
  select(where(is.numeric))
```

Codes for type of Control:

1 = Voluntary Non‐Profit‐Church

2 = Voluntary Non‐Profit‐Other

3 = Proprietary‐Individual

4 = Proprietary‐Corporation

5 = Proprietary‐Partnership

6 = Proprietary‐Other

7 = Governmental‐Federal

8 = Governmental‐City‐County

9 = Governmental‐County

10 = Governmental‐State

11 = Governmental‐Hospital District

12 = Governmental‐City

13 = Governmental‐Other

Codes for Provider Type:

1 = General Short Term (includes CAHs)

2 = General Long Term

3 = Cancer

4 = Psychiatric

5 = Rehabilitation

6 = Religious Non‐Medical Health Care Institution

7 = Children

8 = Reserved for Future Use

9 = Other

10 = Extended Neoplastic Disease Care

11 = Indian Health Services

12 = Rural Emergency Hospital.

# Exploratory Analysis

```{r}
ggplot(hpc_clean, aes(x = total_costs)) +
  geom_histogram() +
  geom_vline(xintercept = median(hpc_clean$total_costs), color = "red") + 
  geom_vline(xintercept = mean(hpc_clean$total_costs), color = "blue")

ggplot(hpc_clean, aes(x = log(total_costs))) +
  geom_histogram() +
  geom_vline(xintercept = median(log(hpc_clean$total_costs)), color = "red") + 
  geom_vline(xintercept = mean(log(hpc_clean$total_costs)), color = "blue")
```

Distribution of response total costs is extremely right-skewed.

Red line = median, blue line = mean

Summary Statistics:

```{r}
summary(hpc_clean)
```

Pairs plot:

```{r}
# # code to generate and save 4K resolution pairwise plot
# png("pairs.png", width=3840, height=2160)
# ggpairs(hpc_dummies)
# dev.off()

# Try pairs plot with log of total costs
data_pairs = hpc_dummies |>
  select(-c(rural, costs_bin, control_bin_Governmental,
            control_bin_Proprietary, provider_bin_Specialized)
         ) |>
  mutate(total_costs = log(total_costs))

ggpairs(data_pairs, progress = FALSE)
```

-   very high pairwise positive collinearity between:
    -   total_days and bed_days, and total_discharges
    -   salaries and employees on payroll
-   total_costs appears to have fairly strong positive linear relationships with:
    -   fte_employees_on_payroll
    -   total_days
    -   bed_days
    -   total_discharges
    -   salaries
-   total_costs appears to have weak or no relationship with:
    -   total_income
    -   total_assets
-   hard to discern any relationships for the categorical predictors
-   for binary response, the predictors which have positive relationships with total cost have a pattern such that response = 0 corresponds to a higher concentration of points with low values of the predictor response = 1 corresponds to a wider range of values for the predictor. This same pattern shows up also for total assets and total income, which did not look associated with continuous total cost.

# Train-test Split

```{r}
set.seed(1)

train_prop = 0.9

n = nrow(hpc_dummies)
n_train = train_prop*n
n_test = n - n_train

hpc_dummies$set = "Train"
hpc_dummies$set[sample(n, n_test, replace = FALSE)] = "Test"
```

# 10-fold split

```{r}
set.seed(1)
folds = floor(seq(1,11, length.out=nrow(hpc_dummies)+1))[1:nrow(hpc_dummies)]
folds = sample(folds, length(folds))

hpc_dummies$fold = folds
```

# Normalize quantitative variables

```{r}
hpc_quant = hpc_dummies |> select(-c(provider_bin_Specialized, control_bin_Governmental, control_bin_Proprietary, costs_bin, rural, set, fold))

hpc_qual = hpc_dummies |> select(c(provider_bin_Specialized, control_bin_Governmental, control_bin_Proprietary, costs_bin, rural, set, fold))

hpc_scaled = as_tibble(scale(hpc_quant) |> cbind(hpc_qual))

df_train = hpc_scaled |>  filter(set == "Train") |> select(-c(set, fold))
df_test = hpc_scaled |> filter(set == "Test") |> select(-c(set, fold))
```

# For all methods:

-   For each method you apply, use 10 fold cross-validation estimate for the test error.
-   discuss assumptions

# Quantitative Outcome Analyses

## Marginal simple linear regressions

```{r}
predictors = select(df_train, -c(total_costs, costs_bin))

# model summaries
map(predictors, ~summary(lm(total_costs ~ .x, data = df_train)))

simple_models = map(predictors, ~lm(total_costs ~ .x, data = df_train))
```

10-fold cv

```{r}

coefficients_df = hpc_scaled |> select(-c(total_costs, costs_bin, set, fold)) |> mutate(across(everything(), as.numeric))
MSE_df = coefficients_df[1:10,]

for (i in 1:10) {
  df_train_i = hpc_scaled |> filter(fold == i) |> select(-c(fold, set))
  predictors = select(df_train_i, -c(total_costs, costs_bin))
  model = map(predictors, ~lm(total_costs ~ .x, data = df_train_i))
  for (j in colnames(predictors)) {
    MSE_df[i,j] = mean((predict(model[[j]]) - df_train_i$total_costs)^2)
  }
}

ten_fold_mean_MSE = MSE_df |> summarize(across(everything(), mean))

ten_fold_mean_MSE
```

Above is MSE averaged over ten fold cross validation for each marginal linear regression on each predictor.

## Multiple linear regression

```{r}
train.X = df_train |> select(-c("costs_bin"))
test.X = df_test |> select(-c("costs_bin"))

lin_model = lm(total_costs ~ ., data=train.X)

summary(lin_model)

pred = predict(lin_model, newdata = test.X)

mean((pred - test.X$total_costs)^2)

erates = rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> 
    select(-c("costs_bin", "fold", "set"))
  
  test.X = hpc_scaled |> filter(fold == i) |> 
    select(-c("costs_bin", "fold", "set"))
  
  lin_model = lm(total_costs ~ ., data=train.X)
  
  pred = predict(lin_model, newdata = test.X)
  
  erates[i] = mean((pred - test.X$total_costs)^2)
}

erates
```

-   Add polynomial terms or transformations of some of the predictors

    ```{r}
    train.X = df_train |> select(-c("costs_bin")) |> 
                          mutate(days2 = total_days^2, salaries2 = salaries^2)
    test.X = df_test |> select(-c("costs_bin")) |> 
                        mutate(days2 = total_days^2, salaries2 = salaries^2)

    lin_model = lm(total_costs ~ ., data=train.X)

    summary(lin_model)

    pred = predict(lin_model, newdata = test.X)

    mean((pred - test.X$total_costs)^2)

    erates = rep(0,10)

    for (i in 1:10) {
      train.X = hpc_scaled |> filter(fold != i) |> 
        select(-c("costs_bin", "fold", "set")) |> 
        mutate(days2 = total_days^2, salaries2 = salaries^2)
      
      test.X = hpc_scaled |> filter(fold == i) |> 
        select(-c("costs_bin", "fold", "set")) |> 
        mutate(days2 = total_days^2, salaries2 = salaries^2)
      
      lin_model = lm(total_costs ~ ., data=train.X)
      
      pred = predict(lin_model, newdata = test.X)
      
      erates[i] = mean((pred - test.X$total_costs)^2)
    }

    erates
    ```

-   Add at least two interaction terms that make sense to you

    ```{r}
    train.X = df_train |> select(-c("costs_bin")) |> 
                          mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)
    test.X = df_test |> select(-c("costs_bin")) |> 
                        mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)

    lin_model = lm(total_costs ~ ., data=train.X)

    summary(lin_model)

    pred = predict(lin_model, newdata = test.X)

    mean((pred - test.X$total_costs)^2)

    erates = rep(0,10)

    for (i in 1:10) {
      train.X = hpc_scaled |> filter(fold != i) |> 
        select(-c("costs_bin", "fold", "set")) |> 
        mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)
      
      test.X = hpc_scaled |> filter(fold == i) |> 
        select(-c("costs_bin", "fold", "set")) |> 
        mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)
      
      lin_model = lm(total_costs ~ ., data=train.X)
      
      pred = predict(lin_model, newdata = test.X)
      
      erates[i] = mean((pred - test.X$total_costs)^2)
    }

    erates
    ```

Both transformations and interaction terms present

```{r}
train.X = df_train |> select(-c("costs_bin")) |> 
                      mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll, days2 = total_days^2, salaries2 = salaries^2)
test.X = df_test |> select(-c("costs_bin")) |> 
                    mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll, days2 = total_days^2, salaries2 = salaries^2)

lin_model = lm(total_costs ~ ., data=train.X)

summary(lin_model)

pred = predict(lin_model, newdata = test.X)

mean((pred - test.X$total_costs)^2)

erates = rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> 
    select(-c("costs_bin", "fold", "set")) |> 
    mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll, days2 = total_days^2, salaries2 = salaries^2)
  
  test.X = hpc_scaled |> filter(fold == i) |> 
    select(-c("costs_bin", "fold", "set")) |> 
    mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll, days2 = total_days^2, salaries2 = salaries^2)
  
  lin_model = lm(total_costs ~ ., data=train.X)
  
  pred = predict(lin_model, newdata = test.X)
  
  erates[i] = mean((pred - test.X$total_costs)^2)
}

erates
```

## Regression Tree (with pruning)

```{r}
{r}
library(tree)
set.seed(1)

train.X = df_train|> select(-c(costs_bin))
test.X = df_test |> select(-c(costs_bin))

tree_mod = tree(total_costs ~ ., data=train.X, control = tree.control(1866496, mincut = 1000),
                split = "gini")

cv_tree = cv.tree(tree_mod)

k = cv.tree(tree_mod)$size[which(cv_tree$dev == min(cv_tree$dev))][1]

print(k)

tree_pruned <- prune.tree(tree_mod, best = k)

pred <- predict(tree_pruned, newdata = test.X)

test_error_classtree <- mean( (test.X$total_costs - pred )^2)

test_error_classtree

erates = rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> mutate(costs_bin = as.factor(costs_bin)) |> filter(fold != i) |> select(-c(fold,set,costs_bin))
  test.X = hpc_scaled |> mutate(costs_bin = as.factor(costs_bin)) |> filter(fold == i) |> select(-c(fold,set,costs_bin))
  
  tree_mod = tree(total_costs ~ ., data=train.X, control = tree.control(1866496, mincut = 1000),
                split = "gini")
  
  tree_pruned <- prune.tree(tree_mod, best = k)
  
  pred <- predict(tree_pruned, newdata = test.X)
  
  erates[i] =  mean( (test.X$total_costs - pred )^2)
}

erates

mean(erates)
```

## Bagging (with variable importance)

```{r}
library(randomForest)
set.seed(1)

train.X = df_train |> select(-costs_bin)
test.X = df_test |> select(-costs_bin)

bag.total_costs = randomForest(total_costs ~ ., data = train.X, mtry = length(train.X)-1)

pred = predict(bag.total_costs, newdata=test.X)

mean((pred - test.X$total_costs)^2)

importance(bag.total_costs)

erates=rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-costs_bin)
  test.X = hpc_scaled |> filter(fold == i) |> select(-costs_bin)

  bag.total_costs = randomForest(total_costs ~ ., data = train.X, mtry = length(train.X)-1)
  
  pred = predict(bag.total_costs, newdata=test.X)
  
  erates[i] = mean((pred - test.X$total_costs)^2)
}

erates

mean(erates)
```

## Random Forest (with variable importance)

```{r}
library(randomForest)
set.seed(1)

train.X = df_train |> select(-costs_bin)
test.X = df_test |> select(-costs_bin)

bag.total_costs = randomForest(total_costs ~ ., data = train.X)

pred = predict(bag.total_costs, newdata=test.X)

mean((pred - test.X$total_costs)^2)

importance(bag.total_costs)

erates=rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-costs_bin)
  test.X = hpc_scaled |> filter(fold == i) |> select(-costs_bin)

  bag.total_costs = randomForest(total_costs ~ ., data = train.X)
  
  pred = predict(bag.total_costs, newdata=test.X)
  
  erates[i] = mean((pred - test.X$total_costs)^2)
}

erates

mean(erates)
```

## Boosting (including selecting the tuning parameter)

```{r}
library(gbm)
set.seed(1)

train.X = df_train |> select(-costs_bin)
test.X = df_test |> select(-costs_bin)

boost.total_costs = gbm(total_costs ~ ., data = train.X, distribution = "gaussian", n.trees = 5000, interaction.depth = 4)

summary(boost.total_costs)

pred = predict(boost.total_costs, newdata=test.X)
```

## Neural Network

# Variable Selection

## Best Subset

```{r}
library(leaps)

erates = matrix(rep(0, 10*12), nrow = 10, ncol = 12)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-c(costs_bin, set, fold))
  test.X = hpc_scaled |> filter(fold == i) |> select(-c(costs_bin, set, fold))
  best_subset = regsubsets(total_costs ~ ., data = train.X, nvmax = ncol(train.X))
  summ = summary(best_subset)
  for (j in 1:ncol(train.X)-1) {
    selected_vars = c("total_costs")
    for (k in 1:ncol(train.X)-1) {
      cond = FALSE
      if (isTRUE(summ$which[,-1][j,k])) {cond = TRUE}
      if (cond == TRUE) {selected_vars = append(selected_vars, colnames(summ$which)[-1][k])}
    }
    temp.X = train.X |> select(all_of(selected_vars))
    lin_model = lm(total_costs ~ ., data=temp.X)
    pred = predict(lin_model, newdata = test.X)
    erates[i,j] = mean((pred - test.X$total_costs)^2)
  }
}

erates = as_tibble(erates) |> summarize(across(V1:V12,mean))

erates

which(erates == min(erates))
```

## Forward Stepwise

```{r}
library(leaps)

erates = matrix(rep(0, 10*12), nrow = 10, ncol = 12)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-c(costs_bin, set, fold))
  test.X = hpc_scaled |> filter(fold == i) |> select(-c(costs_bin, set, fold))
  best_subset = regsubsets(total_costs ~ ., data = train.X, nvmax = ncol(train.X), method="forward")
  summ = summary(best_subset)
  for (j in 1:ncol(train.X)-1) {
    selected_vars = c("total_costs")
    for (k in 1:ncol(train.X)-1) {
      cond = FALSE
      if (isTRUE(summ$which[,-1][j,k])) {cond = TRUE}
      if (cond == TRUE) {selected_vars = append(selected_vars, colnames(summ$which)[-1][k])}
    }
    temp.X = train.X |> select(all_of(selected_vars))
    lin_model = lm(total_costs ~ ., data=temp.X)
    pred = predict(lin_model, newdata = test.X)
    erates[i,j] = mean((pred - test.X$total_costs)^2)
  }
}

erates = as_tibble(erates) |> summarize(across(V1:V12,mean))

erates

which(erates == min(erates))
```

## Backward Stepwise

```{r}
library(leaps)

erates = matrix(rep(0, 10*12), nrow = 10, ncol = 12)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-c(costs_bin, set, fold))
  test.X = hpc_scaled |> filter(fold == i) |> select(-c(costs_bin, set, fold))
  best_subset = regsubsets(total_costs ~ ., data = train.X, nvmax = ncol(train.X), method="backward")
  summ = summary(best_subset)
  for (j in 1:ncol(train.X)-1) {
    selected_vars = c("total_costs")
    for (k in 1:ncol(train.X)-1) {
      cond = FALSE
      if (isTRUE(summ$which[,-1][j,k])) {cond = TRUE}
      if (cond == TRUE) {selected_vars = append(selected_vars, colnames(summ$which)[-1][k])}
    }
    temp.X = train.X |> select(all_of(selected_vars))
    lin_model = lm(total_costs ~ ., data=temp.X)
    pred = predict(lin_model, newdata = test.X)
    erates[i,j] = mean((pred - test.X$total_costs)^2)
  }
}

erates = as_tibble(erates) |> summarize(across(V1:V12,mean))

erates

which(erates == min(erates))
```

(For the above 3 methods, determine which model of a given size is best by comparing the 10-fold cross validation estimate of the test error.)

## Ridge regression (find the best tuning parameter using cross-validation)

### Quantitative

```{r}
library(glmnet)
train.X = hpc_scaled |> select(-c("costs_bin", "set", "fold"))
x = scale(model.matrix(total_costs ~ ., data = train.X)[ , -1])

lambda_grid = 10 ^ seq(10, -2, length = 100)
ridge_reg = cv.glmnet(x, hpc_dummies$total_costs, alpha = 0, type.measure = "mse", lambda = lambda_grid, nfolds=10)
lambda = ridge_reg$lambda.min

ridge_model = glmnet(x, hpc_dummies$total_costs,alpha = 0, lambda = lambda, nfolds=10)

coef(ridge_model)
```

### Qualitative

```{r}
library(glmnet)
train.X = hpc_scaled |> select(-c("total_costs", "set", "fold"))
x = scale(model.matrix(costs_bin ~ ., data = train.X)[ , -1])

lambda_grid = 10 ^ seq(10, -2, length = 100)
ridge_reg = cv.glmnet(x, hpc_scaled$costs_bin, alpha = 0, family="binomial", lambda = lambda_grid, nfolds=10)
lambda = ridge_reg$lambda.min

ridge_model = glmnet(x, hpc_scaled$costs_bin,alpha = 0, lambda = lambda, nfolds=10)

coef(ridge_model)
```

## Lasso (find the best tuning parameter using cross-validation)

### Quantitative

```{r}
library(glmnet)
train.X = hpc_scaled |> select(-c("costs_bin", "set", "fold"))
x = scale(model.matrix(total_costs ~ ., data = train.X)[ , -1])

lambda_grid = 10 ^ seq(10, -2, length = 100)
lasso_reg = cv.glmnet(x, hpc_scaled$total_costs, alpha = 1, type.measure = "mse", lambda = lambda_grid, nfolds=10)

lambda = lasso_reg$lambda.min

lasso_model = glmnet(x, hpc_scaled$total_costs, alpha = 1, lambda = lambda, nfolds=10)

coef(lasso_model)
```

### Qualitative

```{r}
library(glmnet)
train.X = hpc_scaled |> select(-c("total_costs", "set", "fold"))
x = scale(model.matrix(costs_bin ~ ., data = train.X)[ , -1])

lambda_grid = 10 ^ seq(10, -2, length = 100)
lasso_reg = cv.glmnet(x, hpc_scaled$costs_bin, alpha = 1, family="binomial", lambda = lambda_grid, nfolds=10)

lambda = lasso_reg$lambda.min

lasso_model = glmnet(x, hpc_scaled$costs_bin, alpha = 1, lambda = lambda, nfolds=10)

coef(lasso_model)
```

## Principal Components Regression (PCR)

```{r}
library(pls)

train.X = df_train
test.X = df_test

pcr_model = pcr(total_costs ~ ., data = train.X)

pred = predict(pcr_model, newdata = test.X)

mean((pred - test.X$total_costs)^2)


erates = rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-c(set,fold,costs_bin))
  test.X = hpc_scaled |> filter(fold == i) |> select(-c(set,fold,costs_bin))

pcr_model = pcr(total_costs ~ ., data = train.X)

pred = predict(pcr_model, newdata = test.X)

erates[i] = mean((pred - test.X$total_costs)^2)
}

erates

mean(erates)
```

# Qualitative Outcome Analyses

## KNN

```{r}
library(class)
set.seed(1)

K = 25

erates = rep(0,K)

for (i in 1:K) {
  knn.pred = knn(df_train, df_test, df_train$costs_bin, k = i)
  erates[i] = mean(knn.pred != df_test$costs_bin)
}

erates = matrix(rep(0, 10*K), nrow = 10, ncol =K)

for (i in 1:10) {
  for (j in 1:K) {
    train.X = select(filter(hpc_dummies, fold != i), -c("fold", "set"))
    test.X = select(filter(hpc_dummies, fold == i), -c("fold", "set"))
    
    knn.pred = knn(train.X, test.X, train.X$costs_bin, k = j)
   erates[[i,j]] = mean(knn.pred != test.X$costs_bin)
  }
}

as_tibble(erates) |> summarize(across(everything(), mean))
```

## Multiple logistic regression

-   Add polynomial terms or transformations of some of the predictors
-   Add at least two interaction terms that make sense to you

```{r}
suppressWarnings({

train.X = df_train |> select(-c("total_costs"))
test.X = df_test |> select(-c("total_costs"))

logist_model = glm(costs_bin ~ ., data=train.X, family="binomial")

pred = round(predict(logist_model, newdata = test.X, type="response"))

erate = mean(pred != test.X$costs_bin)

erate

})

summary(logist_model)

suppressWarnings({

erates = rep(0, 10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-c("total_costs", "set", "fold"))
  test.X = hpc_scaled |> filter(fold == i) |> select(-c("total_costs", "set", "fold"))

  logist_model = glm(costs_bin ~ ., data=train.X, family="binomial")
  
  pred = round(predict(logist_model, newdata = test.X, type="response"))
  
  erates[i] = mean(pred != test.X$costs_bin)
}

erates
})

erates

mean(erates)
```

```{r}
suppressWarnings({

train.X = df_train |> select(-c("total_costs")) |> 
                      mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)

test.X = df_test |> select(-c("total_costs")) |> mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)

logist_model = glm(costs_bin ~ ., data=train.X, family="binomial")

pred = round(predict(logist_model, newdata = test.X, type="response"))

erate = mean(pred != test.X$costs_bin)

erate

})

suppressWarnings({

erates = rep(0, 10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-c("total_costs", "set", "fold")) |> mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)
  
  test.X = hpc_scaled |> filter(fold == i) |> select(-c("total_costs", "set", "fold")) |> mutate(employees_x_total_income = fte_employees_on_payroll * total_income, specialized_employees_interaction = provider_bin_Specialized * fte_employees_on_payroll)

  logist_model = glm(costs_bin ~ ., data=train.X, family="binomial")
  
  pred = round(predict(logist_model, newdata = test.X, type="response"))
  
  erates[i] = mean(pred != test.X$costs_bin)
}

erates

})


erates

mean(erates)
```

```{r}

suppressWarnings({

train.X = df_train |> select(-c("total_costs")) |> 
                      mutate(days2 = total_days^2, salaries2 = salaries^2)
test.X = df_test |> select(-c("total_costs")) |> 
                    mutate(days2 = total_days^2, salaries2 = salaries^2)

logist_model = glm(costs_bin ~ ., data=train.X, family="binomial")

pred = round(predict(logist_model, newdata = test.X, type="response"))

erate = mean(pred != test.X$costs_bin)

erate

})

suppressWarnings({

erates = rep(0, 10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> 
                      select(-c("total_costs", "set", "fold")) |> 
                      mutate(days2 = total_days^2, salaries2 = salaries^2)
  test.X = hpc_scaled |> filter(fold == i) |> 
                      select(-c("total_costs", "set", "fold")) |> 
                    mutate(days2 = total_days^2, salaries2 = salaries^2)

  logist_model = glm(costs_bin ~ ., data=train.X, family="binomial")
  
  pred = round(predict(logist_model, newdata = test.X, type="response"))
  
  erates[i] = mean(pred != test.X$costs_bin)
}

erates

})

erates

mean(erates)
```

## LDA

```{r}
# sample code for LDA

lda_costs = MASS::lda(costs_bin ~ ., data = df_train)

lda_costs_pred = predict(lda_costs, newdata = select(df_test, -costs_bin))$class

test_error = mean(df_test$costs_bin != lda_costs_pred)

test_error

erates = rep(0, 10)

for (i in 1:10) {
    train.X = select(filter(hpc_dummies, fold != i), -c("fold", "set"))
    test.X = select(filter(hpc_dummies, fold == i), -c("fold", "set"))
    
    lda_costs = MASS::lda(costs_bin ~ ., data = train.X)

    lda_costs_pred = predict(lda_costs, newdata = select(test.X, -c("costs_bin")))$class
    
    erates[i] = mean(lda_costs_pred != test.X$costs_bin)
}

erates

mean(erates)
```

## QDA

```{r}

qda_costs = MASS::qda(costs_bin ~ ., data = df_train)

qda_costs_pred = predict(qda_costs, newdata = select(df_test, -costs_bin))$class

test_error = mean(df_test$costs_bin != qda_costs_pred)

test_error

erates = rep(0, 10)

for (i in 1:10) {
    train.X = select(filter(hpc_dummies, fold != i), -c("total_costs","fold", "set"))
    test.X = select(filter(hpc_dummies, fold == i), -c("total_costs","fold", "set"))
    
    qda_costs = MASS::qda(costs_bin ~ ., data = train.X)

    qda_costs_pred = predict(qda_costs, newdata = select(test.X, -c("costs_bin")))$class
    
    erates[i] = mean(qda_costs_pred != test.X$costs_bin)
}

erates

mean(erates)
```

## Naive Bayes (at least two kernels)

```{r}
library(e1071)
library(naivebayes)

# sample code for naive Bayes gaussian
nb_gaussian = e1071::naiveBayes(costs_bin ~ ., data = df_train)

nb_pred = predict(nb_gaussian, newdata = df_test)

test_error_nb = mean(df_test$costs_bin != nb_pred)

test_error_nb
```

```{r}
erates = rep(0, 10)

for (i in 1:10) {
  train.X = hpc_dummies |> filter(fold != i)
  test.X = hpc_dummies |> filter(fold == i)
  
  nb_gaussian = e1071::naiveBayes(costs_bin ~ ., data = train.X)

  nb_pred = predict(nb_gaussian, newdata = test.X)
  
  erates[i] = mean(test.X$costs_bin != nb_pred)
}

erates
```

```{r}
predictors = select(df_train, -c(total_costs, costs_bin))

predictor_matrix = as.matrix(predictors)

test_matrix = df_test |> select( -c(costs_bin, total_costs) ) |> as.matrix()

nb_KDE =
  nonparametric_naive_bayes(
    y = as.factor(df_train %>% pull(costs_bin)),
    x = predictor_matrix
    )

nb_kde_pred = predict(nb_KDE, newdata = test_matrix )

test_error_nb_kde_pred = mean(df_test$costs_bin != nb_kde_pred)

test_error_nb_kde_pred
```

```{r}

erates = rep(0, 10)

for (i in 1:10) {
  train.X = hpc_dummies |> filter(fold != i)
  test.X = hpc_dummies |> filter(fold == i)
  
  predictors = train.X |> select(-c(total_costs, costs_bin, set))
  
  predictor_matrix = as.matrix(predictors)
  
  test_matrix = test.X |> select(-c(total_costs, costs_bin, set)) |> as.matrix()
  
  nb_KDE =
    nonparametric_naive_bayes(
      y = as.factor(train.X %>% pull(costs_bin)),
      x = predictor_matrix
      )
  
  nb_kde_pred = predict(nb_KDE, newdata = test_matrix)
  
  erates[i] = mean(hpc_dummies[fold == i]$costs_bin != nb_kde_pred)
}

erates

mean(erates)
```

## Decision Tree (with pruning)

```{r}
library(tree)
set.seed(1)

train.X = df_train |> mutate(costs_bin = as.factor(costs_bin)) |> select(-c(total_costs))
test.X = df_test |> mutate(costs_bin = as.factor(costs_bin)) |> select(-c(total_costs))

tree_mod = tree(costs_bin ~ ., data=train.X, control = tree.control(1866496, mincut = 1000),
                split = "gini")

cv_tree = cv.tree(tree_mod)

k = cv.tree(tree_mod)$size[which(cv_tree$dev == min(cv_tree$dev))][1]

print(k)

tree_pruned <- prune.misclass(tree_mod, best = k)

pred <- predict(tree_pruned, newdata = test.X, type = "class")

test_error_classtree <- mean( test.X$costs_bin != pred )

test_error_classtree

table(pred, test.X$costs_bin)

erates = rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> mutate(costs_bin = as.factor(costs_bin)) |> filter(fold != i) |> select(-c(fold,set,total_costs))
  test.X = hpc_scaled |> mutate(costs_bin = as.factor(costs_bin)) |> filter(fold == i) |> select(-c(fold,set,total_costs))
  
  tree_mod = tree(costs_bin ~ ., data=train.X, control = tree.control(1866496, mincut = 1000),
                split = "gini")
  
  tree_pruned <- prune.misclass(tree_mod, best = k)
  
  pred <- predict(tree_pruned, newdata = test.X, type = "class")
  
  erates[i] =  mean( test.X$costs_bin != pred )
}

erates

mean(erates)
```

```         
```

## Bagging (with variable importance)

```         
```

```{r}
library(randomForest)
set.seed(1)

train.X = df_train |> select(-total_costs)
test.X = df_test |> select(-total_costs)

bag.costs_bin = randomForest(costs_bin ~ ., data = train.X, mtry = length(train.X)-1)

pred = predict(bag.costs_bin, newdata=test.X, type="class")

mean(pred != test.X$costs_bin)

importance(bag.costs_bin)

erates=rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-total_costs)
  test.X = hpc_scaled |> filter(fold == i) |> select(-total_costs)

  bag.costs_bin = randomForest(costs_bin ~ ., data = train.X, mtry = length(train.X)-1)
  
  pred = predict(bag.costs_bin, newdata=test.X, type="class")
  
  erates[i] = mean(pred != test.X$costs_bin)
}

erates

mean(erates)
```

## Random Forest (with variable importance)

```{r}
library(randomForest)
set.seed(1)

train.X = df_train |> select(-total_costs)
test.X = df_test |> select(-total_costs)

bag.costs_bin = randomForest(costs_bin ~ ., data = train.X)

pred = predict(bag.costs_bin, newdata=test.X, type="class")

mean(pred != test.X$costs_bin)

importance(bag.costs_bin)

erates=rep(0,10)

for (i in 1:10) {
  train.X = hpc_scaled |> filter(fold != i) |> select(-total_costs)
  test.X = hpc_scaled |> filter(fold == i) |> select(-total_costs)

  bag.costs_bin = randomForest(costs_bin ~ ., data = train.X)
  
  pred = predict(bag.costs_bin, newdata=test.X, type="class")
  
  erates[i] = mean(pred != test.X$costs_bin)
}

erates

mean(erates)
```

## Boosting (including selecting the tuning parameter)

(For the above three methods, calculate the Gini index on each leaf of the final tree to examine the purity of the node.)

```{r}
library(gbm)
set.seed(1)

train.X = hpc_scaled |> select(-total_costs)
test.X = hpc_scaled |> select(-total_costs)

boost.costs_bin = gbm(costs_bin ~ ., data = train.X, distribution = "bernoulli", n.trees = 5000, interaction.depth = 4)

pred = round(predict(boost.costs_bin, newdata=test.X, type="response"))
```

## Neural Network

## Calculate True/False Positive/Negative rates for each method

# Bootstrap CI

# Simulation Study
